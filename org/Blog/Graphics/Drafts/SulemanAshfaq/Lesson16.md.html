*Lesson 16: Projection Transformation*

Matrix discussion & Review
====================================

Review:
------------------------------------
This is a continuation of the part of the course dealing with matrix transformations.

Last time we were able to construct a transformation matrix, the model matrix, that took our quad (which, don't forget, is just a place holder for a real model's mesh, they're identical in theory and practice)
from model space (also known as local space) to world space (our normal coordinate system) and another transformation matrix, the view matrix, that took our quad from world space to view space (also known as eye space).

There is no spoon!:
------------------------------------

Remember the big picture:

A 3D scene rendered by OpenGL must be projected onto the computer screen as a 2D image, this process is called rasterization (rasterization is simply the process of mapping from a normalized space to pixels).
Ultimately, OpenGL is just a complicated rasterization state machine, and at the end of the day, it just maps whatever lies 
within the so called normalized device coordinates (NDC) to the screen.

![NDC space diagram from [Sang Ho Ahn](http://www.songho.ca/opengl/gl_projectionmatrix.html)](NDC.png)

There is no such thing as a camera, there's just a position in space we're choosing to center a matrix transformation around such that its position is inverted back to the origin and 
everything else in the coordinate space has to come along for the ride (everything else needs to correspondingly transform to keep the congruence of space, because that's how reality works. 
The relative position remains constant.)

That's what's really happening under the hood of our matrix library calls ( glm::lookAt() )

This allowed us to turn the whole world around what we choose as the camera's position and simulate a digital camera. These new coordinates are still being culled by the internal rasterization within NDC space.

This is a good first few steps, but we're still limited to the NDC bounds and we still don't have perspective. This will require one more transformation, so let's get to it.

Projection Overview:
------------------------------------

As discussed in previous lessons, all the rendering pipeline matrix transformations are $4$ x $1$ matrices (using the so called homogenous coordinates to encapsulate both rotation and translation in the same transformation)

Recall a vertex position that is being fed to the rendering pipeline looks like this 

$$\vec {vertex} = x \hat i + y\hat j + z \hat k + 1 \hat w $$

or in matrix notation:

$$
\begin{bmatrix}
x \\
y \\
z \\
1
\end{bmatrix}
$$

The perspective transformation is no different and and through the process of projecting onto a frustum accumulates a value in it's $w$'th component, which looks like this:

$$
= \begin{bmatrix}

\frac {2nx} {(r - l)z} -\frac {(r + l)} {r - l} \\
\frac {2ny} {(t - b)z} -\frac {(t + b)} {t - b} \\
\frac {(f + n)} {f - n} - \frac {2fn} {(f-n)z} \\
z
\end{bmatrix}
$$

At the end of the vertex shader stage of the rendering pipeline, vertex vector values generated by previous stages are collected and then clipped to the view volume during vertex post processing.
(See further discussion [here:](https://www.khronos.org/opengl/wiki/Vertex_Post-Processing))<br>
Remember NDC for the all coordinates must be between $-1$ & $1$, thus we must divide by $w$ value to normalize it $\Rightarrow$ :

$$ -w <= x <= w$$
$$ -w <= y <= w$$
$$ -w <= z <= w$$


![Summary of transformation sequence from [learnOpenGL.com](https://learnopengl.com/Getting-started/Coordinate-Systems)](modelViewTransformation.png)

Projection Matrix Implementation:
====================================

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>